{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 2 : Plot and Select Mineral Resources\n",
    "\n",
    "Machine learning algorithms require data to train a predictive model. In this notebook, we are going to select some mineral deposits which we are interested in. And then these selected deposits will be used as input in Step 3 to retrieve attributes from the subduction zone sample points. After that, in Step 4, we can format the data so that they are ready to be fed into the machine learning models in Step 5.\n",
    "\n",
    "Now let's select some interesting mineral deposits and prepare the data for the next step. Step 3 takes a csv file as input, which should contain five columns. \n",
    "\n",
    "* index       -- unique number to identify the deposit\n",
    "* lon         -- the longitude of the deposit\n",
    "* lat         -- the latitude of the deposit\n",
    "* age         -- how old the deposit is\n",
    "* plate id    -- an ID for the tectonic plate in which the deposit resides, this ID is used in plate tectonic reconstruction\n",
    "\n",
    "The ultimate goal of this step is to produce the csv file with the above five columns. There are many ways to get data and prepare the csv file. We are going to show you some examples below. After you have gone through the examples, you should have learnt how to create the csv file. And you are encouraged to come up with your own novel ways to find and process data, for example hack into KGB database, ect. Remember, only the final csv file matters. Focus on the five columns inside the csv file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Use ../data/CopperDeposits/XYBer14_t2_ANDES.shp data\n",
    "\n",
    "This is the simplest example. \n",
    "\n",
    "We just load in data from a shape file and write out the five-column data to a csv file.\n",
    "\n",
    "Run the script to create an example coregistration input file for XYBer14_t2_ANDES.shp dataset.\n",
    "\n",
    "The coregistration input file can be used later in step 3: coregistration.\n",
    "\n",
    "##### The implementation details are in create_coregistration_input_data_example.py.\n",
    "If you would like to know more magic behind the scene, open [create_coregistration_input_data_example.py](create_coregistration_input_data_example.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /workspace/spatio-temporal-exploration-master/python/../data/polygon_south_america.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from parameters import parameters\n",
    "from create_coregistration_input_data_example import *\n",
    "import pygplates\n",
    "import glob\n",
    "\n",
    "#get start time, end time and time step from parameters.py\n",
    "start_time = parameters[\"time\"][\"start\"]\n",
    "end_time = parameters[\"time\"][\"end\"]\n",
    "time_step = parameters[\"time\"][\"step\"]\n",
    "\n",
    "#first, we process the real deposits from XYBer14_t2_ANDES.shp\n",
    "data = process_real_deposits(start_time, end_time, time_step)\n",
    "\n",
    "#then, we copy the real deposits and replace the age with random number\n",
    "#these deposits with random ages will be labeled as non-deposit later\n",
    "##random_data = generate_random_deposits(data, start_time, end_time) COMMENTED BY JULIAN\n",
    "\n",
    "#save negative deposits ALL THIS SECTION COMMENTED BY JULIAN\n",
    "##random_data=pd.DataFrame(random_data, columns=['index', 'lon','lat','age','plate_id'])\n",
    "##random_data = random_data.astype({\"plate_id\": int, \"age\":int}) \n",
    "##random_data.to_csv(Utils.get_coreg_input_dir() + 'negative_deposits.csv', index=False)\n",
    "\n",
    "#save positive deposits\n",
    "data=pd.DataFrame(data, columns=['index', 'lon','lat','age','plate_id'])\n",
    "data = data.astype({\"plate_id\": int, \"age\":int}) \n",
    "data.to_csv(Utils.get_coreg_input_dir() + 'SA_positives_porphiries.csv', index=False)\n",
    "\n",
    "#save deposit candidates\n",
    "deposit_candidates = Utils.get_deposit_candidates()\n",
    "deposit_candidates.to_csv(Utils.get_coreg_input_dir() + 'SA_candidates.csv', index_label = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot a map to see the trench and copper deposits in Andes.\n",
    "\n",
    "Since the deposits are all in Andes, draw the map with extent \"-85, -30, -55, 15\"(South America). The deposits are coloured by their ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "def set_ax(ax):\n",
    "    ax.stock_img()\n",
    "    ax.set_extent([-85, -29, -55, 15])\n",
    "\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                      linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_right = False\n",
    "    gl.xlocator = mticker.FixedLocator([-180, -150, -120, -90, -80, -70, -60,-50,-40,-30, 0, 180])\n",
    "    gl.ylocator = mticker.FixedLocator([-90,-50,-40, -30, -20,-10, 0, 10, 20, 30, 40,50, 90])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'color': 'gray', 'weight': 'bold', 'fontsize': '5'}\n",
    "    gl.ylabel_style = {'color': 'gray', 'weight': 'bold', 'fontsize': '5'}\n",
    "\n",
    "trench_file = Utils.get_convergence_dir() + 'subStats_0.00.csv'\n",
    "trench_data= np.genfromtxt(trench_file, skip_header=1, delimiter=',')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, subplot_kw={'projection': ccrs.PlateCarree()},figsize=(12,12),dpi=150)\n",
    "set_ax(ax1)\n",
    "set_ax(ax2)\n",
    "\n",
    "cb = ax1.scatter(data['lon'], data['lat'], 50, marker='.',c=data['age'],  cmap=plt.cm.jet)\n",
    "cb = ax2.scatter(random_data['lon'], random_data['lat'], 50, marker='.',c=random_data['age'],  cmap=plt.cm.jet)\n",
    "ax1.scatter(trench_data[:,0], trench_data[:,1], 2, marker='.', color='white')# draw the trench in white\n",
    "ax2.scatter(trench_data[:,0], trench_data[:,1], 2, marker='.', color='white')# draw the trench in white\n",
    "ax1.title.set_text('Andes Copper Deposits Coloured By Real Ages')\n",
    "ax2.title.set_text('Andes Copper Deposits Coloured By Random Ages')\n",
    "cbar = fig.colorbar(cb, shrink=0.5, ax=[ax1, ax2], orientation='horizontal', pad=0.05)\n",
    "cbar.set_label('Age(Myr)',size=10)\n",
    "cbar.ax.tick_params(labelsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Extract Data From EarthChem Data\n",
    "\n",
    "In this part, we are going to show you how to extract data from EarthChem database and draw the deposits on a map.\n",
    "\n",
    "We will select deposits which are within a region(5 degrees) of any trench sample point. The data will also be filtered by mineral type.\n",
    "\n",
    "#### Some mineral symbols and their meaning\n",
    "\n",
    "* CU -- Copper\n",
    "* CO2 -- Carbon dioxide\n",
    "* ZN -- Zinc\n",
    "* AU -- Gold\n",
    "* GA -- Gallium\n",
    "* CS -- Caesium\n",
    "* LI -- Lithium\n",
    "* AG -- Sliver\n",
    "\n",
    "#### All the mineral symbols in EarthChem data\n",
    "* SIO2,U234_U238,TIO2,AL2O3,FE2O3,TH230_TH232,FE2O3T,TH232_TH230,FEO,FEOT,MGO,RA228_RA226,CAO,NA2O,K2O,\n",
    "* P2O5,MNO,U238_ACTIVITY,LOI,H2O_PLUS,TH230,H2O_MINUS,H2O,RA226,CR2O3,NIO,LA,CE,CACO3,PR,SM,EU,GD,TB,DY,\n",
    "* HO,ER,TM,YB,U234_U238_ACTIVITY,LU,LI,BE,B,C,CO2,F,CL,K,CA,MG,SC,TI,V,FE,CR,MN,CO,NI,CU,ZN,GA,ZR,GER,SR,\n",
    "* K40_AR36,BI,OS187_OS188,NB,TH232_U238,PB208_PB206,CD,PO210_TH230,U238_PB204,BA,AR40_AR36,W,AR37_AR39,AU,\n",
    "* XE129_XE132,LU176_HF177,HG,OS186_OS188,PB206_PB208,TA,PB210_U238,SB,SR87_SR86,SE,PB207_PB204,PB206_PB204,\n",
    "* PB208_PB204,SN,S,TH230_U238,ND143_ND144,U,RA226_TH230,I,P,Y,EPSILON_ND,MO,OS184_OS188,PD,RA226_TH228,TE,\n",
    "* TH232_PB204,HF,OS187_OS186,CL36_CL,RA228_TH232,PB206_PB207,PB,INDIUM,H,PB210_RA226,AR38_AR36,AR40_AR39,D18O,\n",
    "* AG,TH,U235_PB204,NE21_NE22,TL,NE20_NE22,AS,HF176_HF177,RB,AL,BE10_BE9,AR36_AR39,ND,CS,quartz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import extract_earth_chem\n",
    "from parameters import parameters\n",
    "\n",
    "earth_chem_file = 'EarthChem_all.csv'\n",
    "polygon_points = Utils.get_region_of_interest_polygon().values.flatten()\n",
    "deposit_points = extract_earth_chem.query(earth_chem_file, 'AU', polygon_points)\n",
    "display(deposit_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have selected 44160 copper deposits from the EarthChem database.\n",
    "\n",
    "Do you rememer we need five columns?\n",
    "\n",
    "The EarthChem_CU.csv does not have \"index\" and \"plate id\" columns and it has a extra \"CU\" column.\n",
    "\n",
    "The \"index\" column can be easily generated and the extra \"CU\" column can be dropped. However, the \"plate id\" column is a bit tricky. Let me show you how to deal with it in the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "#first, let's find plate id for those deposits\n",
    "static_polygons = pygplates.FeatureCollection(parameters['static_polygons_file'])\n",
    "rotation_model = pygplates.RotationModel(Utils.get_files(parameters['rotation_files']))\n",
    "plate_ids = Utils.get_plate_id(deposit_points.LONGITUDE.tolist(), deposit_points.LATITUDE.tolist(), \n",
    "                               static_polygons, rotation_model)\n",
    "\n",
    "deposit_points.rename(columns = {'LONGITUDE':'lon', 'AGE':'age', 'LATITUDE':'lat'}, inplace = True) \n",
    "deposit_points.age = np.round(deposit_points.age)\n",
    "deposit_points = deposit_points.astype({\"age\": int}) \n",
    "deposit_points = deposit_points[['lon', 'lat', 'age']]\n",
    "deposit_points['plate_id'] = plate_ids\n",
    "\n",
    "start_time = parameters['time']['start'] \n",
    "end_time = parameters['time']['end']\n",
    "time_step = parameters['time']['step']\n",
    "\n",
    "deposit_points = deposit_points[deposit_points['age']>start_time]\n",
    "deposit_points = deposit_points[deposit_points['age']<end_time]\n",
    "deposit_points.drop_duplicates(inplace=True) \n",
    "deposit_points.reset_index(drop=True, inplace=True)\n",
    "\n",
    "deposit_points.to_csv(Utils.get_coreg_input_dir() + 'positive_deposits.csv', index_label = 'index')\n",
    "deposit_points.age = np.random.randint(start_time+1, end_time, size=len(deposit_points))\n",
    "deposit_points.to_csv(Utils.get_coreg_input_dir() +  'negative_deposits.csv', index_label = 'index')\n",
    "\n",
    "#save deposit candidates\n",
    "deposit_candidates = Utils.get_deposit_candidates()\n",
    "deposit_candidates.to_csv(Utils.get_coreg_input_dir() + 'deposit_candidates.csv', index_label = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the data in EarthChem_CU_all.csv have all the five columns we need. \n",
    "\n",
    "Next, let's plot the data in a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "trench_file = Utils.get_convergence_dir() + 'subStats_0.00.csv'\n",
    "if os.path.isfile(trench_file):\n",
    "    trench_data= np.genfromtxt(trench_file, skip_header=1, delimiter=',')\n",
    "else:\n",
    "    raise Exception(f'\\nERROR: unable to open file {trench_file}. \\nRun Step 1 Generate Subduction Convergence Kinematics Statistics first!')\n",
    "    \n",
    "mesh_points = Utils.get_mesh_points(polygon_points)\n",
    "\n",
    "#plot the data    \n",
    "fig = plt.figure(figsize=(12,8),dpi=96)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "gl.xlocator = mticker.FixedLocator(range(-180,180,10))\n",
    "gl.ylocator = mticker.FixedLocator(range(-90,90,10))\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'color': 'gray', 'weight': 'bold'}\n",
    "gl.ylabel_style = {'color': 'gray', 'weight': 'bold'}\n",
    "\n",
    "ax.stock_img()\n",
    "#ax.set_extent([-180, 180, -90, 90])\n",
    "ax.set_extent(Utils.get_region_of_interest_extent())\n",
    "cb = ax.scatter(deposit_points['lon'], deposit_points['lat'], 50, marker='.',c=deposit_points['age'], vmin=1, vmax=100, cmap=plt.cm.jet)\n",
    "ax.scatter(mesh_points['lon'], mesh_points['lat'], 10, marker='.',color='yellow')\n",
    "ax.scatter(trench_data[:,0], trench_data[:,1], 20, marker='.', color='white')\n",
    "plt.plot(polygon_points[0::2],polygon_points[1::2], transform=ccrs.Geodetic())\n",
    "plt.title('Deposits in North America Coloured by Age(Myr)')\n",
    "fig.colorbar(cb, shrink=0.5, label='Age(Myr)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3: PorCuEX2008.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import pandas as pd\n",
    "import Utils\n",
    "\n",
    "#read in data\n",
    "data = pd.read_csv(\"../data/PorCuEX2008.csv\")\n",
    "trench_data= np.genfromtxt(Utils.get_convergence_dir() + 'subStats_0.00.csv', skip_header=1, delimiter=',')\n",
    "print(f'Data shape: {data.shape}')\n",
    "print('The first 5 rows in the data:')\n",
    "display(data.head())\n",
    "\n",
    "print('All the columns in the data:')\n",
    "print(data.columns)\n",
    "\n",
    "#select deposits within 5 degrees of trench\n",
    "indices = Utils.select_points_in_region(data['LongitudeDecimal'], data['LatitudeDecimal'], \n",
    "                              trench_data[:,0], trench_data[:,1], 5)#5 degrees\n",
    "data_near_trench = data[indices]\n",
    "print(f'Data near trench shape: {data_near_trench.shape}')\n",
    "\n",
    "#select data within bounding box [-85, -30, -55, 15]\n",
    "data_south_america = data_near_trench[data_near_trench['LongitudeDecimal']>-85]\n",
    "data_south_america = data_south_america[data_near_trench['LongitudeDecimal']<-30]\n",
    "data_south_america = data_south_america[data_near_trench['LatitudeDecimal']>-55]\n",
    "data_south_america = data_south_america[data_near_trench['LatitudeDecimal']<5]\n",
    "print(f'Data South America shape: {data_south_america.shape}\\n')\n",
    "\n",
    "#the data_big and data_small do not always have the same length\n",
    "#for example, when there are more than half of the values are zeros, \n",
    "#they should all be considered small values\n",
    "def divide_data(data, column_name):\n",
    "    tmp = data.fillna(value={column_name:0})\n",
    "    data_sorted = tmp.sort_values(by=column_name, ascending=False)\n",
    "    #print(data_sorted[column_name])\n",
    "    middle_value = data_sorted[column_name].values.tolist()[int(data_sorted.shape[0]/2)]\n",
    "    #print(middle_value)\n",
    "    data_big = data_sorted[data_sorted[column_name]>middle_value]\n",
    "    data_small = data_sorted[data_sorted[column_name]<=middle_value]\n",
    "    #print(f'big {column_name}: \\n', data_big[column_name])\n",
    "    #print(f'small {column_name}: \\n', data_small[column_name])\n",
    "    return data_big, data_small\n",
    "\n",
    "#divide data by Tonnage\n",
    "big_tonnage, small_tonnage = divide_data(data_near_trench, 'Tonnage')\n",
    "\n",
    "#We can do the same to 'Copper grade', 'Molybdenum grade', 'Gold grade', 'Silver grade'\n",
    "big_copper_percent, small_copper_percent = divide_data(data_near_trench, 'Copper grade')\n",
    "big_molybdenum_percent, small_molybdenum_percent = divide_data(data_near_trench, 'Molybdenum grade')\n",
    "big_gold_percent, small_gold_percent = divide_data(data_near_trench, 'Gold grade')\n",
    "big_silver_percent, small_siler_percent = divide_data(data_near_trench, 'Silver grade')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the data in a global map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************\n",
    "\n",
    "#LOOK HERE!!\n",
    "#you may choose the data to plot\n",
    "#only keep the one line which you want uncommented\n",
    "\n",
    "#plot_data = data\n",
    "plot_data = data_near_trench\n",
    "#plot_data = data_south_america\n",
    "#plot_data = big_tonnage\n",
    "#plot_data = small_tonnage\n",
    "#plot_data = big_copper_percent \n",
    "#plot_data = small_copper_percent\n",
    "#plot_data = big_molybdenum_percent\n",
    "#plot_data = small_molybdenum_percent\n",
    "#plot_data = big_gold_percent\n",
    "#plot_data = small_gold_percent\n",
    "#plot_data = big_silver_percent\n",
    "#plot_data = small_siler_percent \n",
    "#*******************************************\n",
    "\n",
    "\n",
    "#plot the map\n",
    "fig = plt.figure(figsize=(16,12),dpi=150)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_left = False\n",
    "gl.xlocator = mticker.FixedLocator([-180, -150, -120, -90, -60, -30, 0, 30, 60, 90, 120, 150, 180])\n",
    "gl.ylocator = mticker.FixedLocator([-90, -75, -60, -45, -30, -15, 0, 15, 30, 45, 60, 75, 90])\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'color': 'gray', 'weight': 'bold'}\n",
    "gl.ylabel_style = {'color': 'gray', 'weight': 'bold'}\n",
    "\n",
    "ax.stock_img()\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "#ax.set_extent([-85, -29, -55, 15])\n",
    "cb = ax.scatter(plot_data['LongitudeDecimal'], plot_data['LatitudeDecimal'], 50, marker='.',c=plot_data['AgeMY'], \n",
    "                vmin=1, vmax=100, cmap=plt.cm.jet)\n",
    "ax.scatter(trench_data[:,0], trench_data[:,1], 5, marker='.', color='white')\n",
    "plt.title('Deposits Near the Subduction Zones Coloured by Age(Myr)')\n",
    "fig.colorbar(cb, shrink=0.5, label='Age(Myr)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot a regional map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide data by Tonnage\n",
    "big_tonnage, small_tonnage = divide_data(data_south_america, 'Tonnage')\n",
    "\n",
    "#We can do the same to 'Copper grade', 'Molybdenum grade', 'Gold grade', 'Silver grade'\n",
    "big_copper_percent, small_copper_percent = divide_data(data_south_america, 'Copper grade')\n",
    "big_molybdenum_percent, small_molybdenum_percent = divide_data(data_south_america, 'Molybdenum grade')\n",
    "big_gold_percent, small_gold_percent = divide_data(data_south_america, 'Gold grade')\n",
    "big_silver_percent, small_siler_percent = divide_data(data_south_america, 'Silver grade')\n",
    "\n",
    "#*******************************************\n",
    "\n",
    "#LOOK HERE!!\n",
    "#you may choose the data to plot\n",
    "#only keep the one line which you want uncommented\n",
    "\n",
    "#plot_data = data_south_america\n",
    "plot_data = big_tonnage\n",
    "#plot_data = small_tonnage\n",
    "#plot_data = big_copper_percent \n",
    "#plot_data = small_copper_percent\n",
    "#plot_data = big_molybdenum_percent\n",
    "#plot_data = small_molybdenum_percent\n",
    "#plot_data = big_gold_percent\n",
    "#plot_data = small_gold_percent\n",
    "#plot_data = big_silver_percent\n",
    "#plot_data = small_siler_percent \n",
    "#******************************************\n",
    "\n",
    "#plot the map\n",
    "fig = plt.figure(figsize=(6,6),dpi=150)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.stock_img()\n",
    "ax.set_extent([-85, -29, -55, 15])\n",
    "#ax.set_extent([-180, 180, -90, 90])\n",
    "data=data[:155]\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "gl.xlocator = mticker.FixedLocator([-180, -150, -120, -90, -80, -70, -60,-50,-40,-30, 0, 180])\n",
    "gl.ylocator = mticker.FixedLocator([-90,-50,-40, -30, -20,-10, 0, 10, 20, 30, 40,50, 90])\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'color': 'gray', 'weight': 'bold', 'fontsize': '5'}\n",
    "gl.ylabel_style = {'color': 'gray', 'weight': 'bold', 'fontsize': '5'}\n",
    "\n",
    "cb = ax.scatter(plot_data['LongitudeDecimal'], plot_data['LatitudeDecimal'], 20, marker='.',\n",
    "                c=plot_data['AgeMY'], vmin=1, vmax=100, cmap=plt.cm.jet)\n",
    "ax.scatter(trench_data[:,0], trench_data[:,1], 2, marker='.', color='white')# draw the trench in white\n",
    "plt.title('Deposits Near the Subduction Zones Coloured By Age',fontsize=7)\n",
    "cbar = fig.colorbar(cb, shrink=0.5)\n",
    "cbar.set_label('Age(Myr)',size=10)\n",
    "cbar.ax.tick_params(labelsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add random age deposits and trench points. The PorCuEX2008_south_america.csv is ready to be used in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygplates\n",
    "#first, let's find plate id for those deposits\n",
    "\n",
    "static_polygons = pygplates.FeatureCollection(parameters['static_polygons_file'])\n",
    "rotation_model = pygplates.RotationModel(Utils.get_files(parameters['rotation_files']))\n",
    "plate_ids = Utils.get_plate_id(data_south_america.LongitudeDecimal.tolist(), \n",
    "                               data_south_america.LatitudeDecimal.tolist(), \n",
    "                               static_polygons, \n",
    "                               rotation_model)\n",
    "\n",
    "ages = np.round(data_south_america.AgeMY)\n",
    "indices = list(range(len(ages)))\n",
    "\n",
    "data=np.c_[indices,data_south_america.LongitudeDecimal,data_south_america.LatitudeDecimal, ages, plate_ids]\n",
    "data=data[~np.isnan(data).any(axis=1)].tolist()\n",
    "#then, we copy the real deposits and replace the age with random number\n",
    "#these deposits with random ages will be labeled as non-deposit later\n",
    "random_data = generate_random_deposits(data, start_time, end_time)\n",
    "\n",
    "#save negative deposits\n",
    "random_data=pd.DataFrame(random_data, columns=['index', 'lon','lat','age','plate_id'])\n",
    "random_data = random_data.astype({\"plate_id\": int, \"age\":int}) \n",
    "random_data.to_csv(Utils.get_coreg_input_dir() + '/negative_deposits_PorCuEX2008.csv', index=False)\n",
    "\n",
    "#save positive deposits\n",
    "data=pd.DataFrame(data, columns=['index', 'lon','lat','age','plate_id'])\n",
    "data = data.astype({\"plate_id\": int, \"age\":int}) \n",
    "data.to_csv(Utils.get_coreg_input_dir() + '/positive_deposits_PorCuEX2008.csv', index=False)\n",
    "\n",
    "#save deposit candidates\n",
    "deposit_candidates = Utils.get_deposit_candidates()\n",
    "deposit_candidates.to_csv(Utils.get_coreg_input_dir() + 'deposit_candidates_PorCuEX2008.csv', index_label = 'index')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the end of step 2 and now open the step 3 notebook -- \"3_Coregistration.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
